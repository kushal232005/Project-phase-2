import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# Generate sample demo data
def generate_fake_aqi_data(n=1000):
    np.random.seed(42)
    data = pd.DataFrame({
        'PM2.5': np.random.uniform(10, 200, n),
        'PM10': np.random.uniform(20, 300, n),
        'NO2': np.random.uniform(5, 100, n),
        'SO2': np.random.uniform(1, 50, n),
        'CO': np.random.uniform(0.2, 2.0, n),
        'O3': np.random.uniform(10, 120, n),
        'temperature': np.random.uniform(5, 40, n),
        'humidity': np.random.uniform(20, 90, n),
        'wind_speed': np.random.uniform(0.5, 10, n)
    })

    # Simulate AQI as a weighted sum + noise
    data['AQI'] = (
        0.4 * data['PM2.5'] + 
        0.3 * data['PM10'] + 
        0.1 * data['NO2'] + 
        0.05 * data['SO2'] +
        0.05 * data['O3'] +
        np.random.normal(0, 10, n)
    ).round(2)

    return data

# Load or generate data
data = generate_fake_aqi_data()

# Define features and target
features = ['PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'O3', 'temperature', 'humidity', 'wind_speed']
X = data[features]
y = data['AQI']

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train XGBoost model
model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluate
print(f"R2 Score: {r2_score(y_test, y_pred):.3f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.3f}")

# Feature Importance
xgb.plot_importance(model)
plt.title("Feature Importance")
plt.show()

# Correlation heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(data[features + ['AQI']].corr(), annot=True, cmap='coolwarm')
plt.title("Feature Correlation with AQI")
plt.show()
